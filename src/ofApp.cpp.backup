#include "ofApp.h"

//--------------------------------------------------------------
void ofApp::setup(){
	ofSetFrameRate(60);  // Let app run at 60fps for responsiveness
	ofSetBackgroundColor(0, 255, 0);
	
	// Initialize video mode flags
	useVideoFile = false;
	videoLoaded = false;
	videoPaused = false;
	currentVideoPath = "";
	
	// Initialize polygon drawing system
	isDrawingPolygon = false;
	currentColorIndex = 0;
	
	// Initialize YOLO detection system
	yoloSession = nullptr;
	yoloLoaded = false;
	enableDetection = false;
	frameSkipCounter = 0;
	detectionFrameSkip = 2;  // Process every 2nd frame for ~30fps detection
	lastDetectionTime = 0.0f;
	detectionErrorCount = 0;
	
	// Load YOLO model
	loadYOLOModel();
	
	// Try to load test video file first (optional)
	videoPlayer.load("test_video.mp4");
	if (videoPlayer.isLoaded()) {
		videoLoaded = true;
		videoPlayer.setLoopState(OF_LOOP_NORMAL);
		videoPlayer.setVolume(0.0f);  // Mute audio
		videoPlayer.play();
		videoPaused = false;
		useVideoFile = true;  // Start with video if available
		currentVideoPath = "test_video.mp4";
		ofLogNotice() << "Test video loaded: test_video.mp4 (audio muted)";
	} else {
		ofLogNotice() << "No test video found, will use camera. Press 'o' to open video file.";
	}
	
	// Initialize camera at its maximum supported framerate
	camera.setDesiredFrameRate(30);
	camera.setup(640, 480);
	
	// Check if camera connected
	cameraConnected = camera.isInitialized();
	
	if (!cameraConnected && !videoLoaded) {
		ofLogError() << "Neither camera nor test video available!";
	} else if (!cameraConnected) {
		ofLogNotice() << "Camera not available, using video file only";
	}
}

//--------------------------------------------------------------
void ofApp::update(){
	if (useVideoFile && videoLoaded) {
		videoPlayer.update();
	} else if (cameraConnected) {
		camera.update();
	}
	
	// Process YOLO detection
	if (enableDetection && yoloLoaded) {
		processYOLODetection();
	}
}

//--------------------------------------------------------------
void ofApp::draw(){
	// Draw video source
	if (useVideoFile && videoLoaded) {
		videoPlayer.draw(0, 0, ofGetWidth(), ofGetHeight());
	} else if (cameraConnected) {
		camera.draw(0, 0, ofGetWidth(), ofGetHeight());
	}
	
	// Draw polygons over video
	drawPolygons();
	
	// Draw object detections
	if (enableDetection && yoloLoaded) {
		drawDetections();
	}
	
	// Draw FPS counter
	ofDrawBitmapStringHighlight("App FPS: " + ofToString(ofGetFrameRate(), 1), 10, 20, ofColor::black, ofColor::white);
	
	// Draw source status
	string source = useVideoFile ? "Source: Video File" : "Source: Camera";
	ofColor sourceColor = (useVideoFile && videoLoaded) || (!useVideoFile && cameraConnected) ? ofColor::green : ofColor::red;
	ofDrawBitmapStringHighlight(source, 10, 40, ofColor::black, sourceColor);
	
	// Draw camera status
	string cameraStatus = cameraConnected ? "Camera: Available" : "Camera: Not Available";
	ofColor cameraColor = cameraConnected ? ofColor::green : ofColor::yellow;
	ofDrawBitmapStringHighlight(cameraStatus, 10, 60, ofColor::black, cameraColor);
	
	// Draw video status
	string videoStatus = videoLoaded ? "Video: Available" : "Video: Not Available";
	ofColor videoColor = videoLoaded ? ofColor::green : ofColor::yellow;
	ofDrawBitmapStringHighlight(videoStatus, 10, 80, ofColor::black, videoColor);
	
	// Draw current source info
	if (useVideoFile && videoLoaded) {
		ofDrawBitmapStringHighlight("Video Size: " + ofToString(videoPlayer.getWidth()) + "x" + ofToString(videoPlayer.getHeight()), 10, 100, ofColor::black, ofColor::white);
		ofDrawBitmapStringHighlight("Video Position: " + ofToString(videoPlayer.getPosition(), 2), 10, 120, ofColor::black, ofColor::white);
	} else if (cameraConnected) {
		ofDrawBitmapStringHighlight("Camera Size: " + ofToString(camera.getWidth()) + "x" + ofToString(camera.getHeight()), 10, 100, ofColor::black, ofColor::white);
		ofDrawBitmapStringHighlight("Frame New: " + string(camera.isFrameNew() ? "YES" : "NO"), 10, 120, ofColor::black, ofColor::white);
	}
	
	// Draw current file info
	if (useVideoFile && videoLoaded && !currentVideoPath.empty()) {
		string filename = ofFilePath::getFileName(currentVideoPath);
		ofDrawBitmapStringHighlight("Current Video: " + filename, 10, 140, ofColor::black, ofColor::white);
		string playStatus = videoPaused ? "PAUSED" : "PLAYING";
		ofDrawBitmapStringHighlight("Status: " + playStatus, 10, 160, ofColor::black, ofColor::white);
		ofDrawBitmapStringHighlight("Position: " + ofToString(videoPlayer.getPosition(), 2) + " / 1.0", 10, 180, ofColor::black, ofColor::white);
	}
	
	// Draw instructions
	ofDrawBitmapStringHighlight("Press 'o' to open video file", 10, 200, ofColor::black, ofColor::white);
	ofDrawBitmapStringHighlight("Press 'v' to toggle video/camera", 10, 220, ofColor::black, ofColor::white);
	ofDrawBitmapStringHighlight("Press 'r' to restart camera", 10, 240, ofColor::black, ofColor::white);
	if (useVideoFile && videoLoaded) {
		ofDrawBitmapStringHighlight("Press SPACE to play/pause video", 10, 260, ofColor::black, ofColor::white);
		ofDrawBitmapStringHighlight("Press LEFT/RIGHT to seek video", 10, 280, ofColor::black, ofColor::white);
		ofDrawBitmapStringHighlight("Press 'l' to toggle loop mode", 10, 300, ofColor::black, ofColor::white);
	}
	
	// Draw YOLO detection info
	string yoloStatus = yoloLoaded ? (enableDetection ? "YOLO: ON" : "YOLO: Loaded (OFF)") : "YOLO: Failed to load";
	ofColor yoloColor = yoloLoaded ? (enableDetection ? ofColor::green : ofColor::yellow) : ofColor::red;
	ofDrawBitmapStringHighlight(yoloStatus, 10, 400, ofColor::black, yoloColor);
	
	if (yoloLoaded) {
		ofDrawBitmapStringHighlight("Detections: " + ofToString(detections.size()), 10, 420, ofColor::black, ofColor::white);
		ofDrawBitmapStringHighlight("Frame skip: " + ofToString(frameSkipCounter) + "/" + ofToString(detectionFrameSkip), 10, 440, ofColor::black, ofColor::white);
		
		// Detection rate info already shown in status
	}
	
	// Draw polygon controls and info
	ofDrawBitmapStringHighlight("Left-click: Add point | Right-click: Finish polygon", 10, 320, ofColor::black, ofColor::white);
	ofDrawBitmapStringHighlight("Press 'c' to clear all polygons", 10, 340, ofColor::black, ofColor::white);
	ofDrawBitmapStringHighlight("Press 'd' to toggle YOLO detection", 10, 440, ofColor::black, ofColor::white);
	
	// Draw polygon stats
	string polygonInfo = "Polygons: " + ofToString(polygons.size()) + " | Current points: " + ofToString(currentPolygon.size());
	ofDrawBitmapStringHighlight(polygonInfo, 10, 360, ofColor::black, ofColor::white);
	
	if (isDrawingPolygon && currentPolygon.size() > 0) {
		ofDrawBitmapStringHighlight("Drawing polygon " + ofToString(polygons.size() + 1), 10, 380, ofColor::black, ofColor::yellow);
	}
}

//--------------------------------------------------------------
void ofApp::exit(){
	// Clean up ONNX session
	if (yoloSession) {
		delete yoloSession;
		yoloSession = nullptr;
	}
}

//--------------------------------------------------------------
ofApp::~ofApp() {
	// Clean up ONNX session in destructor as well
	if (yoloSession) {
		delete yoloSession;
		yoloSession = nullptr;
	}
}

//--------------------------------------------------------------
void ofApp::keyPressed(int key){
	if (key == 'r' || key == 'R') {
		// Restart camera
		camera.close();
		camera.setDesiredFrameRate(30);
		camera.setup(640, 480);
		cameraConnected = camera.isInitialized();
		
		if (cameraConnected) {
			ofLogNotice() << "Camera restarted successfully";
		} else {
			ofLogError() << "Camera restart failed";
		}
	}
	
	if (key == 'v' || key == 'V') {
		// Toggle between video file and camera
		if (videoLoaded && cameraConnected) {
			useVideoFile = !useVideoFile;
			string newSource = useVideoFile ? "video file" : "camera";
			ofLogNotice() << "Switched to " << newSource;
		} else if (videoLoaded && !useVideoFile) {
			useVideoFile = true;
			ofLogNotice() << "Switched to video file (camera not available)";
		} else if (cameraConnected && useVideoFile) {
			useVideoFile = false;
			ofLogNotice() << "Switched to camera (video not available)";
		} else {
			ofLogWarning() << "Cannot toggle - only one source available";
		}
	}
	
	if (key == 'o' || key == 'O') {
		// Open file dialog to choose video file
		ofFileDialogResult result = ofSystemLoadDialog("Select Video File", false, ofToDataPath("", true));
		if (result.bSuccess) {
			loadVideoFile(result.getPath());
		}
	}
	
	if (key == ' ') {
		// Toggle play/pause for video
		if (useVideoFile && videoLoaded) {
			if (videoPaused) {
				videoPlayer.play();
				videoPaused = false;
				ofLogNotice() << "Video resumed";
			} else {
				videoPlayer.stop();
				videoPaused = true;
				ofLogNotice() << "Video paused";
			}
		}
	}
	
	if (key == OF_KEY_LEFT) {
		// Seek backward
		if (useVideoFile && videoLoaded) {
			float currentPos = videoPlayer.getPosition();
			float newPos = MAX(0.0f, currentPos - 0.1f);  // Go back 10% for more noticeable movement
			
			// Always ensure video is playing when seeking
			if (videoPaused) {
				videoPlayer.play();
			}
			
			videoPlayer.setPosition(newPos);
			
			// Small delay to let seek complete
			ofSleepMillis(50);
			
			// Restore pause state
			if (videoPaused) {
				videoPlayer.stop();
			}
			
			ofLogNotice() << "Seeking backward: " << currentPos << " -> " << newPos;
		}
	}
	
	if (key == OF_KEY_RIGHT) {
		// Seek forward
		if (useVideoFile && videoLoaded) {
			float currentPos = videoPlayer.getPosition();
			float newPos = MIN(1.0f, currentPos + 0.1f);  // Go forward 10% for more noticeable movement
			
			// Always ensure video is playing when seeking
			if (videoPaused) {
				videoPlayer.play();
			}
			
			videoPlayer.setPosition(newPos);
			
			// Small delay to let seek complete
			ofSleepMillis(50);
			
			// Restore pause state
			if (videoPaused) {
				videoPlayer.stop();
			}
			
			ofLogNotice() << "Seeking forward: " << currentPos << " -> " << newPos;
		}
	}
	
	if (key == 'l' || key == 'L') {
		// Toggle loop mode
		if (useVideoFile && videoLoaded) {
			if (videoPlayer.getLoopState() == OF_LOOP_NORMAL) {
				videoPlayer.setLoopState(OF_LOOP_NONE);
				ofLogNotice() << "Loop mode: OFF";
			} else {
				videoPlayer.setLoopState(OF_LOOP_NORMAL);
				ofLogNotice() << "Loop mode: ON";
			}
		}
	}
	
	if (key == 'c' || key == 'C') {
		// Clear all polygons
		polygons.clear();
		polygonColors.clear();
		currentPolygon.clear();
		isDrawingPolygon = false;
		currentColorIndex = 0;
		ofLogNotice() << "All polygons cleared";
	}
	
	if (key == 'd' || key == 'D') {
		// Toggle YOLO detection
		if (yoloLoaded) {
			enableDetection = !enableDetection;
			string status = enableDetection ? "enabled" : "disabled";
			ofLogNotice() << "YOLO detection " << status;
		} else {
			ofLogWarning() << "YOLO model not loaded - cannot enable detection";
		}
	}
}

//--------------------------------------------------------------
void ofApp::keyReleased(int key){

}

//--------------------------------------------------------------
void ofApp::mouseMoved(int x, int y ){

}

//--------------------------------------------------------------
void ofApp::mouseDragged(int x, int y, int button){

}

//--------------------------------------------------------------
void ofApp::mousePressed(int x, int y, int button){
	if (button == 0) { // Left click
		// Add point to current polygon
		currentPolygon.push_back(ofPoint(x, y));
		isDrawingPolygon = true;
		ofLogNotice() << "Added point: (" << x << ", " << y << ") to polygon " << (polygons.size() + 1);
	} else if (button == 2) { // Right click
		// Finish current polygon and start new one
		if (currentPolygon.size() >= 3) {
			polygons.push_back(currentPolygon);
			polygonColors.push_back(getNextPolygonColor());
			ofLogNotice() << "Finished polygon " << polygons.size() << " with " << currentPolygon.size() << " points";
			
			currentPolygon.clear();
			isDrawingPolygon = false;
		} else if (currentPolygon.size() > 0) {
			ofLogWarning() << "Polygon needs at least 3 points to finish";
		}
	}
}

//--------------------------------------------------------------
void ofApp::mouseReleased(int x, int y, int button){

}

//--------------------------------------------------------------
void ofApp::mouseScrolled(int x, int y, float scrollX, float scrollY){

}

//--------------------------------------------------------------
void ofApp::mouseEntered(int x, int y){

}

//--------------------------------------------------------------
void ofApp::mouseExited(int x, int y){

}

//--------------------------------------------------------------
void ofApp::windowResized(int w, int h){

}

//--------------------------------------------------------------
void ofApp::gotMessage(ofMessage msg){

}

//--------------------------------------------------------------
void ofApp::dragEvent(ofDragInfo dragInfo){ 

}


//--------------------------------------------------------------
void ofApp::loadVideoFile(string path) {
	ofLogNotice() << "Attempting to load video: " << path;
	
	// Stop current video if playing
	if (videoLoaded) {
		videoPlayer.stop();
		videoPlayer.close();
	}
	
	// Try to load new video
	videoPlayer.load(path);
	
	if (videoPlayer.isLoaded()) {
		videoLoaded = true;
		currentVideoPath = path;
		videoPlayer.setLoopState(OF_LOOP_NORMAL);
		videoPlayer.setVolume(0.0f);  // Mute audio
		videoPlayer.play();
		videoPaused = false;
		useVideoFile = true;  // Switch to video mode
		
		string filename = ofFilePath::getFileName(path);
		ofLogNotice() << "Successfully loaded video: " << filename;
		ofLogNotice() << "Video size: " << videoPlayer.getWidth() << "x" << videoPlayer.getHeight();
		ofLogNotice() << "Video duration: " << videoPlayer.getDuration() << " seconds";
	} else {
		videoLoaded = false;
		currentVideoPath = "";
		ofLogError() << "Failed to load video: " << path;
		ofLogError() << "Make sure the file is a valid video format (mp4, mov, avi, etc.)";
		
		// Fall back to camera if available
		if (cameraConnected) {
			useVideoFile = false;
			ofLogNotice() << "Falling back to camera";
		}
	}
}

//--------------------------------------------------------------
void ofApp::drawPolygons() {
	// Draw completed polygons
	for (int i = 0; i < polygons.size(); i++) {
		if (polygons[i].size() >= 3) {
			// Set polygon color with transparency
			ofSetColor(polygonColors[i], 100);
			
			// Draw filled polygon
			ofBeginShape();
			for (auto& point : polygons[i]) {
				ofVertex(point.x, point.y);
			}
			ofEndShape(true);
			
			// Draw polygon outline
			ofSetColor(polygonColors[i], 255);
			ofSetLineWidth(2);
			ofNoFill();
			ofBeginShape();
			for (auto& point : polygons[i]) {
				ofVertex(point.x, point.y);
			}
			ofEndShape(true);
			ofFill();
			
			// Draw polygon number
			if (polygons[i].size() > 0) {
				ofPoint center = polygons[i][0];
				for (int j = 1; j < polygons[i].size(); j++) {
					center += polygons[i][j];
				}
				center /= polygons[i].size();
				ofSetColor(255, 255, 255);
				ofDrawBitmapString("Z" + ofToString(i + 1), center.x - 10, center.y + 4);
			}
		}
	}
	
	// Draw current polygon being drawn
	if (currentPolygon.size() > 0) {
		ofColor currentColor = getNextPolygonColor();
		
		// Draw points of current polygon
		ofSetColor(currentColor, 200);
		ofSetLineWidth(3);
		if (currentPolygon.size() > 1) {
			for (int i = 1; i < currentPolygon.size(); i++) {
				ofDrawLine(currentPolygon[i-1], currentPolygon[i]);
			}
		}
		
		// Draw all points as circles
		for (auto& point : currentPolygon) {
			ofDrawCircle(point, 4);
		}
		
		// Draw line from last point to mouse if drawing
		if (isDrawingPolygon) {
			ofSetColor(currentColor, 150);
			ofSetLineWidth(1);
			ofDrawLine(currentPolygon.back(), ofPoint(ofGetMouseX(), ofGetMouseY()));
		}
		
		// Highlight first point if we have enough points to close
		if (currentPolygon.size() >= 3) {
			ofSetColor(255, 255, 0);
			ofDrawCircle(currentPolygon[0], 6);
		}
	}
	
	// Reset drawing state
	ofSetColor(255);
	ofSetLineWidth(1);
	ofFill();
}

//--------------------------------------------------------------
ofColor ofApp::getNextPolygonColor() {
	vector<ofColor> colors = {
		ofColor::red,
		ofColor::blue,
		ofColor::green,
		ofColor::orange,
		ofColor::purple,
		ofColor::cyan,
		ofColor::yellow,
		ofColor::magenta
	};
	
	ofColor color = colors[currentColorIndex % colors.size()];
	if (currentPolygon.size() == 0) { // Only increment when starting new polygon
		currentColorIndex++;
	}
	return color;
}

//--------------------------------------------------------------
void ofApp::loadYOLOModel() {
	ofLogNotice() << "Loading YOLO model...";
	
	// Initialize ONNX Runtime environment
	ortEnv = Ort::Env(ORT_LOGGING_LEVEL_WARNING, "YOLOv8");
	
	// Load class names from coco.names - use data path
	string cocoNamesPath = ofToDataPath("models/coco.names", true);
	ofLogNotice() << "Looking for coco.names at: " << cocoNamesPath;
	ofBuffer buffer = ofBufferFromFile(cocoNamesPath);
	if (buffer.size() > 0) {
		for (auto& line : buffer.getLines()) {
			if (!line.empty()) {
				classNames.push_back(line);
			}
		}
		ofLogNotice() << "Loaded " << classNames.size() << " class names";
	} else {
		ofLogError() << "Failed to load coco.names from: " << cocoNamesPath;
		return;
	}
	
	// Load YOLO model - use absolute data path
	string modelPath = ofToDataPath("models/yolov8n.onnx", true);
	ofLogNotice() << "Looking for YOLO model at: " << modelPath;
	
	try {
		// Create session options
		Ort::SessionOptions sessionOptions;
		sessionOptions.SetIntraOpNumThreads(1);
		sessionOptions.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_EXTENDED);
		
		// Create session
		yoloSession = new Ort::Session(ortEnv, modelPath.c_str(), sessionOptions);
		yoloLoaded = true;
		ofLogNotice() << "YOLO model loaded successfully: " << modelPath;
	} catch (const Ort::Exception& e) {
		ofLogError() << "Failed to load YOLO model: " << e.what();
		yoloLoaded = false;
		yoloSession = nullptr;
	}
}

//--------------------------------------------------------------
void ofApp::processYOLODetection() {
	// Skip frames for performance
	frameSkipCounter++;
	if (frameSkipCounter < detectionFrameSkip) {
		return;
	}
	frameSkipCounter = 0;
	
	// Debug: Log that we're processing
	static int processLogCounter = 0;
	if (processLogCounter++ % 30 == 0) {
		ofLogNotice() << "YOLO: Processing frame " << processLogCounter;
	}
	
	// Timing safety - limit detection frequency
	float currentTime = ofGetElapsedTimef();
	if (currentTime - lastDetectionTime < 0.033f) { // Minimum 33ms between detections (~30fps)
		return;
	}
	lastDetectionTime = currentTime;
	
	// Disable detection if too many errors
	if (detectionErrorCount > 10) {
		ofLogError() << "Too many detection errors (" << detectionErrorCount << ") - permanently disabling";
		enableDetection = false;
		return;
	}
	
	// Clear previous detections safely
	try {
		detections.clear();
	} catch (...) {
		ofLogError() << "Error clearing detections";
		return;
	}
	
	// Validate YOLO session
	if (!yoloSession) {
		ofLogError() << "YOLO session is null - disabling detection";
		enableDetection = false;
		return;
	}
	
	// Get current frame with validation
	ofPixels pixels;
	try {
		if (useVideoFile && videoLoaded && videoPlayer.isLoaded()) {
			pixels = videoPlayer.getPixels();
		} else if (cameraConnected && camera.isInitialized()) {
			pixels = camera.getPixels();
		}
	} catch (...) {
		ofLogError() << "Error getting pixels from video source";
		return;
	}
	
	if (pixels.size() == 0 || pixels.getWidth() == 0 || pixels.getHeight() == 0) {
		ofLogWarning() << "Invalid pixel data - skipping detection";
		return;
	}
	
	try {
		// Prepare input tensor (640x640 for YOLOv8)
		const int inputSize = 640;
		ofImage inputImage;
		
		// Safe image processing
		try {
			inputImage.setFromPixels(pixels);
			inputImage.resize(inputSize, inputSize);
			inputImage.setImageType(OF_IMAGE_COLOR);
		} catch (...) {
			ofLogError() << "Error processing input image";
			return;
		}
		
		// Convert to tensor format - proper NCHW layout
		auto inputPixels = inputImage.getPixels();
		if (inputPixels.size() == 0) {
			ofLogError() << "Input image has no pixels";
			return;
		}
		
		vector<float> inputData;
		try {
			inputData.resize(inputSize * inputSize * 3);
			
			// Correct NCHW tensor layout and normalize to 0-1 range
			for (int y = 0; y < inputSize; y++) {
				for (int x = 0; x < inputSize; x++) {
					int pixelIdx = y * inputSize + x;
					ofColor color = inputPixels.getColor(x, y);
					
					// NCHW format: [batch, channel, height, width]
					inputData[pixelIdx] = color.r / 255.0f;                                    // R channel
					inputData[inputSize * inputSize + pixelIdx] = color.g / 255.0f;           // G channel  
					inputData[2 * inputSize * inputSize + pixelIdx] = color.b / 255.0f;       // B channel
				}
			}
		} catch (...) {
			ofLogError() << "Error creating input tensor data";
			return;
		}
		
		// Run inference with ONNX Runtime - wrapped in additional safety
		try {
			Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);
			
			// Create input tensor
			vector<int64_t> inputShape = {1, 3, inputSize, inputSize};
			Ort::Value inputTensor = Ort::Value::CreateTensor<float>(memoryInfo, inputData.data(), inputData.size(), inputShape.data(), inputShape.size());
			
			// Get input/output names
			const char* inputNames[] = {"images"};
			const char* outputNames[] = {"output0"};
			
			// Run inference with timeout protection
			auto outputs = yoloSession->Run(Ort::RunOptions{nullptr}, inputNames, &inputTensor, 1, outputNames, 1);
			
			if (outputs.empty() || !outputs[0].IsTensor()) {
				ofLogError() << "Invalid ONNX output";
				return;
			}
			
			// Extract output data safely
			float* outputData = outputs[0].GetTensorMutableData<float>();
			if (!outputData) {
				ofLogError() << "Null output data from ONNX";
				return;
			}
			
			auto outputShape = outputs[0].GetTensorTypeAndShapeInfo().GetShape();
			
			// Only log shape occasionally to reduce noise
			static int shapeLogCounter = 0;
			if (shapeLogCounter++ % 60 == 0) { // Log every 60 frames (~2 seconds)
				ofLogNotice() << "YOLO output shape: [" << outputShape[0] << ", " << outputShape[1] << ", " << outputShape[2] << "]";
			}
			
			// YOLOv8 output format: [1, 84, 8400] where 84 = 4 bbox + 80 classes
			// BUT: The actual format might be [8400, 84] - let's handle both cases
			if (outputShape.size() >= 2) {
				int numDetections, numFeatures;
				bool isTransposed = false;
				
				if (outputShape.size() == 3 && outputShape[1] == 84 && outputShape[2] == 8400) {
					// Format: [1, 84, 8400] - transposed
					numDetections = outputShape[2]; // 8400 detections
					numFeatures = outputShape[1];   // 84 features
					isTransposed = true;
					ofLogNotice() << "Using transposed format [1, 84, 8400]";
				} else if (outputShape.size() == 2 && outputShape[0] == 8400 && outputShape[1] == 84) {
					// Format: [8400, 84] - normal
					numDetections = outputShape[0]; // 8400 detections
					numFeatures = outputShape[1];   // 84 features
					isTransposed = false;
					ofLogNotice() << "Using normal format [8400, 84]";
				} else {
					ofLogError() << "Unexpected output shape - cannot parse detections";
					return;
				}
				
				int numClasses = numFeatures - 4; // 80 classes (84 - 4 bbox coords)
				float confThreshold = 0.3f; // Lower threshold to ensure we see detections
				
				// Scale factors to convert to display coordinates
				// Video gets scaled to fit display - we need to account for this
				float videoDisplayScaleX = (float)ofGetWidth() / pixels.getWidth();
				float videoDisplayScaleY = (float)ofGetHeight() / pixels.getHeight();
				
				// Scale from YOLO input size to original video size, then to display
				float scaleX = (float)pixels.getWidth() / inputSize * videoDisplayScaleX;
				float scaleY = (float)pixels.getHeight() / inputSize * videoDisplayScaleY;
				
				// Store detections before NMS filtering
				vector<Detection> rawDetections;
				
				// Add debug info occasionally
				static int debugCounter = 0;
				if (debugCounter++ % 120 == 0) { // Every 4 seconds
					ofLogNotice() << "=== DETECTION DEBUG ===";
					ofLogNotice() << "Video size: " << pixels.getWidth() << "x" << pixels.getHeight();
					ofLogNotice() << "Display size: " << ofGetWidth() << "x" << ofGetHeight();
					ofLogNotice() << "Video->Display scale: X=" << videoDisplayScaleX << ", Y=" << videoDisplayScaleY;
					ofLogNotice() << "Final scale factors: X=" << scaleX << ", Y=" << scaleY;
					ofLogNotice() << "Confidence threshold: " << confThreshold;
					ofLogNotice() << "YOLO input size: " << inputSize << "x" << inputSize;
				}
				
				// Limit detection processing to prevent memory issues
				int maxDetectionsToProcess = (numDetections < 2000) ? numDetections : 2000;
				
				for (int i = 0; i < maxDetectionsToProcess; i++) {
					try {
						float x_center, y_center, width, height;
						
						if (isTransposed) {
							// Transposed format: [1, 84, 8400]
							if (i >= 8400) continue;
							x_center = outputData[i];                    // [0, i]
							y_center = outputData[8400 + i];             // [1, i] 
							width = outputData[2 * 8400 + i];            // [2, i]
							height = outputData[3 * 8400 + i];           // [3, i]
						} else {
							// Normal format: [8400, 84]
							if (i * 84 + 83 >= outputShape[0] * outputShape[1]) continue;
							x_center = outputData[i * 84 + 0];           // [i, 0]
							y_center = outputData[i * 84 + 1];           // [i, 1]
							width = outputData[i * 84 + 2];              // [i, 2]
							height = outputData[i * 84 + 3];             // [i, 3]
						}
						
						// Validate coordinates before processing
						if (!isfinite(x_center) || !isfinite(y_center) || !isfinite(width) || !isfinite(height)) {
							continue;
						}
						
						// Convert from normalized coordinates to pixel coordinates
						x_center *= inputSize;
						y_center *= inputSize;
						width *= inputSize;
						height *= inputSize;
						
						// Scale to original image size
						x_center *= scaleX;
						y_center *= scaleY;
						width *= scaleX;
						height *= scaleY;
						
						// Find best class and confidence from class scores
						float maxConf = 0.0f;
						int bestClass = 0;
						
						for (int c = 0; c < numClasses && c < 80; c++) {
							float classConf;
							
							if (isTransposed) {
								int idx = (4 + c) * 8400 + i;
								if (idx >= outputShape[1] * outputShape[2]) continue;
								classConf = outputData[idx];
							} else {
								int idx = i * 84 + (4 + c);
								if (idx >= outputShape[0] * outputShape[1]) continue;
								classConf = outputData[idx];
							}
							
							if (isfinite(classConf) && classConf > maxConf) {
								maxConf = classConf;
								bestClass = c;
							}
						}
						
						// Filter by confidence threshold and vehicle classes only
						// Vehicle classes: car=2, motorcycle=3, bus=5, truck=7
						bool isVehicle = (bestClass == 2 || bestClass == 3 || bestClass == 5 || bestClass == 7);
						
						if (maxConf > confThreshold && bestClass < classNames.size() && isVehicle) {
							// Additional validation for reasonable bounding box size
							if (width > 20 && height > 20 && width < ofGetWidth() && height < ofGetHeight()) {
								
								// Convert from center format to top-left format
								float x = x_center - width / 2.0f;
								float y = y_center - height / 2.0f;
								
								// Clamp to display boundaries
								x = ofClamp(x, 0, ofGetWidth() - width);
								y = ofClamp(y, 0, ofGetHeight() - height);
								width = ofClamp(width, 20, ofGetWidth() - x);
								height = ofClamp(height, 20, ofGetHeight() - y);
								
								Detection det;
								det.box.set(x, y, width, height);
								det.confidence = maxConf;
								det.classId = bestClass;
								det.className = classNames[bestClass];
								
								// Store in raw detections for NMS processing
								if (rawDetections.size() < 100) { // Allow more before NMS
									rawDetections.push_back(det);
								}
							}
						}
					} catch (...) {
						// Skip this detection if any error occurs
						continue;
					}
				}
				
				// Apply Non-Maximum Suppression (NMS) to remove duplicate detections  
				vector<Detection> filteredDetections;
				applyNMS(rawDetections, filteredDetections, 0.5f); // Higher NMS threshold for fewer false positives
				detections = filteredDetections; // Replace detections with filtered results
				
				// Always log detection info for debugging
				static int detectLogCounter = 0;
				if (detectLogCounter++ % 15 == 0) { // Log every 15 frames (~0.5 seconds)
					ofLogNotice() << "Raw detections: " << rawDetections.size() << ", After NMS: " << detections.size();
					if (rawDetections.size() > 0) {
						ofLogNotice() << "First raw detection: conf=" << rawDetections[0].confidence 
								  << ", class=" << rawDetections[0].className;
					}
				}
				
			} else {
				ofLogError() << "Unexpected YOLO output shape - disabling detection";
				enableDetection = false;
				return;
			}
			
			// Apply Non-Maximum Suppression (NMS) to remove duplicate detections  
			vector<Detection> filteredDetections;
			applyNMS(rawDetections, filteredDetections, 0.5f); // Higher NMS threshold for fewer false positives
			detections = filteredDetections; // Replace detections with filtered results
			
			// Always log detection info for debugging
			static int detectLogCounter = 0;
			if (detectLogCounter++ % 15 == 0) { // Log every 15 frames (~0.5 seconds)
				ofLogNotice() << "Raw detections: " << rawDetections.size() << ", After NMS: " << detections.size();
				if (rawDetections.size() > 0) {
					ofLogNotice() << "First raw detection: conf=" << rawDetections[0].confidence 
								  << ", class=" << rawDetections[0].className;
				}
			}
			
		} catch (const Ort::Exception& e) {
			ofLogError() << "ONNX Runtime error: " << e.what();
			detectionErrorCount++;
			if (detectionErrorCount > 5) {
				enableDetection = false; // Disable after 5 ONNX errors
			}
		} catch (const std::bad_alloc& e) {
			ofLogError() << "Memory allocation error in YOLO detection: " << e.what();
			detectionErrorCount++;
			enableDetection = false; // Disable immediately on memory errors
		} catch (...) {
			ofLogError() << "Unknown error in ONNX inference";
			detectionErrorCount++;
			if (detectionErrorCount > 3) {
				enableDetection = false; // Disable after 3 unknown errors
			}
		}
		
	} catch (...) {
		ofLogError() << "Critical error in YOLO detection - disabling";
		detectionErrorCount += 5; // Heavy penalty for critical errors
		enableDetection = false;
		detections.clear();
	}
}

//--------------------------------------------------------------
void ofApp::applyNMS(const vector<Detection>& rawDetections, vector<Detection>& filteredDetections, float nmsThreshold) {
	filteredDetections.clear();
	
	if (rawDetections.empty()) {
		return;
	}
	
	// Create indices sorted by confidence (highest first)
	vector<int> indices;
	for (int i = 0; i < rawDetections.size(); i++) {
		indices.push_back(i);
	}
	
	// Sort by confidence descending
	std::sort(indices.begin(), indices.end(), [&rawDetections](int a, int b) {
		return rawDetections[a].confidence > rawDetections[b].confidence;
	});
	
	vector<bool> suppressed(rawDetections.size(), false);
	
	for (int i = 0; i < indices.size(); i++) {
		int idx = indices[i];
		if (suppressed[idx]) continue;
		
		// This detection is not suppressed, so add it
		filteredDetections.push_back(rawDetections[idx]);
		
		// Calculate IoU with remaining detections and suppress overlapping ones
		for (int j = i + 1; j < indices.size(); j++) {
			int other_idx = indices[j];
			if (suppressed[other_idx]) continue;
			
			// Calculate Intersection over Union (IoU)
			float iou = calculateIoU(rawDetections[idx].box, rawDetections[other_idx].box);
			
			// Suppress if IoU is above threshold AND same class
			if (iou > nmsThreshold && rawDetections[idx].classId == rawDetections[other_idx].classId) {
				suppressed[other_idx] = true;
			}
		}
	}
}

//--------------------------------------------------------------
float ofApp::calculateIoU(const ofRectangle& box1, const ofRectangle& box2) {
	// Calculate intersection rectangle
	float x1 = std::max(box1.x, box2.x);
	float y1 = std::max(box1.y, box2.y);
	float x2 = std::min(box1.x + box1.width, box2.x + box2.width);
	float y2 = std::min(box1.y + box1.height, box2.y + box2.height);
	
	// No intersection
	if (x2 <= x1 || y2 <= y1) {
		return 0.0f;
	}
	
	// Calculate areas
	float intersectionArea = (x2 - x1) * (y2 - y1);
	float box1Area = box1.width * box1.height;
	float box2Area = box2.width * box2.height;
	float unionArea = box1Area + box2Area - intersectionArea;
	
	// Avoid division by zero
	if (unionArea <= 0.0f) {
		return 0.0f;
	}
	
	return intersectionArea / unionArea;
}

//--------------------------------------------------------------
void ofApp::drawDetections() {
	if (detections.empty()) {
		return;
	}
	
	for (const auto& detection : detections) {
		// Validate detection box coordinates
		if (detection.box.width <= 0 || detection.box.height <= 0) {
			continue;
		}
		
		// Clamp coordinates to screen bounds
		float x = ofClamp(detection.box.x, 0, ofGetWidth() - detection.box.width);
		float y = ofClamp(detection.box.y, 0, ofGetHeight() - detection.box.height);
		float w = ofClamp(detection.box.width, 1, ofGetWidth() - x);
		float h = ofClamp(detection.box.height, 1, ofGetHeight() - y);
		
		// Choose color based on vehicle type
		ofColor boxColor;
		switch (detection.classId) {
			case 2: // car
				boxColor = ofColor(0, 255, 0, 220); // Green
				break;
			case 3: // motorcycle  
				boxColor = ofColor(255, 255, 0, 220); // Yellow
				break;
			case 5: // bus
				boxColor = ofColor(255, 0, 0, 220); // Red
				break;
			case 7: // truck
				boxColor = ofColor(0, 0, 255, 220); // Blue
				break;
			default:
				boxColor = ofColor(255, 255, 255, 220); // White
				break;
		}
		
		// Draw bounding box with vehicle-specific color
		ofSetColor(boxColor);
		ofSetLineWidth(3);
		ofNoFill();
		ofDrawRectangle(x, y, w, h);
		ofFill();
		
		// Draw confidence bar (small bar next to detection)
		float confBarWidth = 60;
		float confBarHeight = 8;
		float confBarX = x + w + 5;
		float confBarY = y;
		
		// Background of confidence bar
		ofSetColor(50, 50, 50, 180);
		ofDrawRectangle(confBarX, confBarY, confBarWidth, confBarHeight);
		
		// Filled portion based on confidence
		ofSetColor(boxColor);
		ofDrawRectangle(confBarX, confBarY, confBarWidth * detection.confidence, confBarHeight);
		
		// Draw class label and confidence
		string label = detection.className + " " + ofToString(detection.confidence, 2);
		float labelWidth = label.length() * 8;
		float labelHeight = 20;
		
		// Ensure label background fits on screen
		float labelX = ofClamp(x, 0, ofGetWidth() - labelWidth);
		float labelY = ofClamp(y - labelHeight, labelHeight, ofGetHeight());
		
		// Draw label background
		ofSetColor(boxColor.r, boxColor.g, boxColor.b, 180);
		ofDrawRectangle(labelX, labelY - labelHeight, labelWidth, labelHeight);
		
		// Draw label text
		ofSetColor(0, 0, 0); // Black text
		ofDrawBitmapString(label, labelX + 2, labelY - 5);
	}
	
	// Reset drawing state
	ofSetColor(255);
	ofSetLineWidth(1);
	ofFill();
}
